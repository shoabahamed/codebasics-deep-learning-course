{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b196d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import necessary modules \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48cd1e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056</td>\n",
       "      <td>2</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2600</td>\n",
       "      <td>4</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>62.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1521</td>\n",
       "      <td>3</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1200</td>\n",
       "      <td>2</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  bedrooms   price\n",
       "0  1056         2   39.07\n",
       "1  2600         4  120.00\n",
       "2  1440         3   62.00\n",
       "3  1521         3   75.00\n",
       "4  1200         2   51.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/codebasics/deep-learning-keras-tf-tutorial/master/8_sgd_vs_gd/homeprices_banglore.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9c08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('price', axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e72e207b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08827586, 0.25      ],\n",
       "       [0.62068966, 0.75      ],\n",
       "       [0.22068966, 0.5       ],\n",
       "       [0.24862069, 0.5       ],\n",
       "       [0.13793103, 0.25      ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets scale the data first\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "scaled_x = x_scaler.fit_transform(x)\n",
    "scaled_y = y_scaler.fit_transform(y.values.reshape(len(y), 1))\n",
    "\n",
    "scaled_x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9245047",
   "metadata": {},
   "source": [
    "<h2>Mean squared Error</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d35a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_predicted):\n",
    "#     accepts two 1-D arrays\n",
    "    total_loss = np.sum((y_true - y_predicted)**2)\n",
    "    \n",
    "    return total_loss / len(y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b47a87",
   "metadata": {},
   "source": [
    "<h2>Minibatch gradient descent</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "78441362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(scaled_x,  scaled_y.reshape(-1, ), \n",
    "                                        random_state=10, test_size=0.2)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c342d693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31851852, 0.51851852, 0.05925926, 0.22222222, 0.51111111,\n",
       "       0.13333333, 0.20740741, 0.11851852, 0.        , 0.04444444,\n",
       "       0.8       , 0.65185185, 0.05237037, 0.07407407, 0.14074074,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3be0d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5085d05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch of 0 the cost is 0.245 and w = [0.997 0.995] and bias = -0.009643269476372925\n",
      "For epoch of 1 the cost is 0.148 and w = [0.995 0.992] and bias = -0.016990564719198617\n",
      "For epoch of 2 the cost is 0.337 and w = [0.99  0.985] and bias = -0.02757038865828755\n",
      "For epoch of 3 the cost is 0.211 and w = [0.986 0.981] and bias = -0.03534830356396891\n",
      "For epoch of 4 the cost is 0.219 and w = [0.982 0.976] and bias = -0.04396373903025649\n",
      "For epoch of 5 the cost is 0.164 and w = [0.979 0.973] and bias = -0.05069750318598426\n",
      "For epoch of 6 the cost is 0.164 and w = [0.977 0.97 ] and bias = -0.05829631063895234\n",
      "For epoch of 7 the cost is 0.297 and w = [0.971 0.963] and bias = -0.06793258752856951\n",
      "For epoch of 8 the cost is 0.282 and w = [0.965 0.956] and bias = -0.07731264392546247\n",
      "For epoch of 9 the cost is 0.157 and w = [0.962 0.953] and bias = -0.08376787390874058\n",
      "For epoch of 10 the cost is 0.132 and w = [0.961 0.949] and bias = -0.09076197834679794\n",
      "For epoch of 11 the cost is 0.2 and w = [0.957 0.944] and bias = -0.0974090267097379\n",
      "For epoch of 12 the cost is 0.129 and w = [0.954 0.94 ] and bias = -0.10291133837087339\n",
      "For epoch of 13 the cost is 0.249 and w = [0.948 0.934] and bias = -0.11233995493912129\n",
      "For epoch of 14 the cost is 0.102 and w = [0.947 0.931] and bias = -0.11841365847884411\n",
      "For epoch of 15 the cost is 0.069 and w = [0.945 0.929] and bias = -0.12200436588448155\n",
      "For epoch of 16 the cost is 0.068 and w = [0.944 0.927] and bias = -0.12688036919420914\n",
      "For epoch of 17 the cost is 0.103 and w = [0.941 0.924] and bias = -0.13198980708304475\n",
      "For epoch of 18 the cost is 0.116 and w = [0.938 0.92 ] and bias = -0.1384320239152141\n",
      "For epoch of 19 the cost is 0.196 and w = [0.933 0.915] and bias = -0.1463946513122937\n",
      "For epoch of 20 the cost is 0.074 and w = [0.931 0.912] and bias = -0.15004604247234343\n",
      "For epoch of 21 the cost is 0.059 and w = [0.93 0.91] and bias = -0.15437100881986518\n",
      "For epoch of 22 the cost is 0.038 and w = [0.929 0.909] and bias = -0.15654331999544863\n",
      "For epoch of 23 the cost is 0.051 and w = [0.928 0.907] and bias = -0.16070824459308933\n",
      "For epoch of 24 the cost is 0.169 and w = [0.923 0.901] and bias = -0.16677998521561477\n",
      "For epoch of 25 the cost is 0.15 and w = [0.919 0.896] and bias = -0.17316266052175133\n",
      "For epoch of 26 the cost is 0.105 and w = [0.916 0.893] and bias = -0.17815406385727112\n",
      "For epoch of 27 the cost is 0.108 and w = [0.913 0.889] and bias = -0.18210856142005907\n",
      "For epoch of 28 the cost is 0.127 and w = [0.909 0.885] and bias = -0.1867003781406605\n",
      "For epoch of 29 the cost is 0.068 and w = [0.907 0.883] and bias = -0.18981200942468274\n",
      "For epoch of 30 the cost is 0.024 and w = [0.906 0.882] and bias = -0.1922282574686219\n",
      "For epoch of 31 the cost is 0.067 and w = [0.905 0.879] and bias = -0.19698073481379128\n",
      "For epoch of 32 the cost is 0.035 and w = [0.904 0.878] and bias = -0.19996052965703115\n",
      "For epoch of 33 the cost is 0.017 and w = [0.903 0.877] and bias = -0.20208099391984505\n",
      "For epoch of 34 the cost is 0.039 and w = [0.903 0.875] and bias = -0.20529177451300437\n",
      "For epoch of 35 the cost is 0.057 and w = [0.901 0.873] and bias = -0.2092629801141187\n",
      "For epoch of 36 the cost is 0.086 and w = [0.898 0.869] and bias = -0.21369522941024321\n",
      "For epoch of 37 the cost is 0.048 and w = [0.896 0.867] and bias = -0.21633655034587823\n",
      "For epoch of 38 the cost is 0.051 and w = [0.895 0.866] and bias = -0.2185560789995699\n",
      "For epoch of 39 the cost is 0.104 and w = [0.892 0.862] and bias = -0.22387971156192954\n",
      "For epoch of 40 the cost is 0.032 and w = [0.891 0.86 ] and bias = -0.22496887806497298\n",
      "For epoch of 41 the cost is 0.034 and w = [0.889 0.859] and bias = -0.22791715193540074\n",
      "For epoch of 42 the cost is 0.019 and w = [0.889 0.858] and bias = -0.2300979113786915\n",
      "For epoch of 43 the cost is 0.026 and w = [0.888 0.857] and bias = -0.23229757197981496\n",
      "For epoch of 44 the cost is 0.031 and w = [0.887 0.855] and bias = -0.2347470705126992\n",
      "For epoch of 45 the cost is 0.043 and w = [0.885 0.854] and bias = -0.23656784141580092\n",
      "For epoch of 46 the cost is 0.021 and w = [0.884 0.852] and bias = -0.23885085773959452\n",
      "For epoch of 47 the cost is 0.075 and w = [0.881 0.849] and bias = -0.24311095405739858\n",
      "For epoch of 48 the cost is 0.016 and w = [0.881 0.848] and bias = -0.2444394544273348\n",
      "For epoch of 49 the cost is 0.017 and w = [0.88  0.847] and bias = -0.2463494987369033\n",
      "For epoch of 50 the cost is 0.079 and w = [0.877 0.844] and bias = -0.2488022461388753\n",
      "For epoch of 51 the cost is 0.014 and w = [0.877 0.843] and bias = -0.24998313079685733\n",
      "For epoch of 52 the cost is 0.03 and w = [0.876 0.843] and bias = -0.2502858297510724\n",
      "For epoch of 53 the cost is 0.042 and w = [0.875 0.841] and bias = -0.25170611615153254\n",
      "For epoch of 54 the cost is 0.021 and w = [0.874 0.84 ] and bias = -0.2536281896016996\n",
      "For epoch of 55 the cost is 0.013 and w = [0.874 0.839] and bias = -0.25550331318839054\n",
      "For epoch of 56 the cost is 0.022 and w = [0.873 0.838] and bias = -0.255724982879082\n",
      "For epoch of 57 the cost is 0.049 and w = [0.871 0.836] and bias = -0.2578669210364622\n",
      "For epoch of 58 the cost is 0.026 and w = [0.871 0.835] and bias = -0.2584584370326937\n",
      "For epoch of 59 the cost is 0.021 and w = [0.87  0.834] and bias = -0.2598020515922021\n",
      "For epoch of 60 the cost is 0.032 and w = [0.869 0.833] and bias = -0.26033545558071264\n",
      "For epoch of 61 the cost is 0.026 and w = [0.869 0.832] and bias = -0.26087124524721605\n",
      "For epoch of 62 the cost is 0.025 and w = [0.868 0.832] and bias = -0.26084234018068964\n",
      "For epoch of 63 the cost is 0.01 and w = [0.868 0.831] and bias = -0.26145627093421525\n",
      "For epoch of 64 the cost is 0.019 and w = [0.867 0.83 ] and bias = -0.26276157653917015\n",
      "For epoch of 65 the cost is 0.028 and w = [0.866 0.83 ] and bias = -0.2629689580231494\n",
      "For epoch of 66 the cost is 0.055 and w = [0.864 0.827] and bias = -0.2664038596591024\n",
      "For epoch of 67 the cost is 0.055 and w = [0.862 0.825] and bias = -0.26735296735763864\n",
      "For epoch of 68 the cost is 0.043 and w = [0.86  0.823] and bias = -0.26991366830916547\n",
      "For epoch of 69 the cost is 0.016 and w = [0.859 0.822] and bias = -0.271489254390757\n",
      "For epoch of 70 the cost is 0.052 and w = [0.857 0.819] and bias = -0.275076701491346\n",
      "For epoch of 71 the cost is 0.046 and w = [0.854 0.816] and bias = -0.27770241141801644\n",
      "For epoch of 72 the cost is 0.015 and w = [0.854 0.815] and bias = -0.27889252090644867\n",
      "For epoch of 73 the cost is 0.015 and w = [0.853 0.815] and bias = -0.2794151763710669\n",
      "For epoch of 74 the cost is 0.01 and w = [0.853 0.814] and bias = -0.27993177637238725\n",
      "For epoch of 75 the cost is 0.036 and w = [0.851 0.812] and bias = -0.2819966540252436\n",
      "For epoch of 76 the cost is 0.043 and w = [0.849 0.81 ] and bias = -0.28441389819746293\n",
      "For epoch of 77 the cost is 0.047 and w = [0.847 0.808] and bias = -0.28509445420475327\n",
      "For epoch of 78 the cost is 0.014 and w = [0.847 0.808] and bias = -0.2860029510170284\n",
      "For epoch of 79 the cost is 0.014 and w = [0.846 0.807] and bias = -0.2866901925875755\n",
      "For epoch of 80 the cost is 0.012 and w = [0.846 0.807] and bias = -0.28662565246305605\n",
      "For epoch of 81 the cost is 0.025 and w = [0.845 0.806] and bias = -0.2863647363023446\n",
      "For epoch of 82 the cost is 0.042 and w = [0.842 0.803] and bias = -0.2894332278309224\n",
      "For epoch of 83 the cost is 0.035 and w = [0.84  0.801] and bias = -0.29230944435514444\n",
      "For epoch of 84 the cost is 0.035 and w = [0.839 0.799] and bias = -0.2945884431636968\n",
      "For epoch of 85 the cost is 0.009 and w = [0.838 0.799] and bias = -0.2947947070514649\n",
      "For epoch of 86 the cost is 0.01 and w = [0.838 0.798] and bias = -0.295515246323882\n",
      "For epoch of 87 the cost is 0.012 and w = [0.837 0.798] and bias = -0.2958316151318626\n",
      "For epoch of 88 the cost is 0.007 and w = [0.837 0.797] and bias = -0.29646075153720003\n",
      "For epoch of 89 the cost is 0.007 and w = [0.836 0.797] and bias = -0.29674833169404957\n",
      "For epoch of 90 the cost is 0.006 and w = [0.836 0.797] and bias = -0.29735813174891634\n",
      "For epoch of 91 the cost is 0.006 and w = [0.836 0.796] and bias = -0.2982187621618856\n",
      "For epoch of 92 the cost is 0.012 and w = [0.835 0.795] and bias = -0.299464500056239\n",
      "For epoch of 93 the cost is 0.03 and w = [0.833 0.793] and bias = -0.3020453731220979\n",
      "For epoch of 94 the cost is 0.03 and w = [0.831 0.791] and bias = -0.30435031089515624\n",
      "For epoch of 95 the cost is 0.027 and w = [0.831 0.791] and bias = -0.30413345252871826\n",
      "For epoch of 96 the cost is 0.007 and w = [0.83 0.79] and bias = -0.30447152431835023\n",
      "For epoch of 97 the cost is 0.009 and w = [0.83 0.79] and bias = -0.3050151314487024\n",
      "For epoch of 98 the cost is 0.01 and w = [0.83 0.79] and bias = -0.3043868785533194\n",
      "For epoch of 99 the cost is 0.004 and w = [0.83  0.789] and bias = -0.30491241615270953\n"
     ]
    }
   ],
   "source": [
    "def minibatch_gradient_descent(x_train, y_true, epochs=1000, learning_rate=0.01):\n",
    "    number_of_features = x_train.shape[1]\n",
    "    w = np.ones(number_of_features)\n",
    "    bias = 0\n",
    "    \n",
    "    for index in range(epochs):\n",
    "        \n",
    "        positions = random.sample(range(0, len(x_train)), k=5)\n",
    "        \n",
    "        total_samples = len(positions)\n",
    "        new_x_train = x_train[positions]\n",
    "        new_y_true = y_true[positions]\n",
    "        \n",
    "        y_pred = np.dot(w, new_x_train.T) + bias\n",
    "        cost = mean_squared_error(new_y_true, y_pred)\n",
    "        \n",
    "        w_grad = -(2/total_samples) * (new_x_train.T.dot(new_y_true - y_pred))\n",
    "        bias_grad = -(2/total_samples) * np.sum(new_y_true - y_pred)\n",
    "        \n",
    "        w = w - learning_rate * w_grad\n",
    "        bias = bias - learning_rate * bias_grad\n",
    "        \n",
    "        print(f'For epoch of {index} the cost is {round(cost, 3)} and w = {np.round(w, 3)} and bias = {bias}')\n",
    "        if cost <= 0.005:\n",
    "            break\n",
    "            \n",
    "    return w, bias\n",
    "        \n",
    "w, bias = minibatch_gradient_descent(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f1116677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00242494]\n",
      " [ 0.37591601]\n",
      " [-0.00169052]\n",
      " [ 0.83992314]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.dot(w, x_test.T) + bias\n",
    "print(y_pred.reshape(len(y_pred), 1))\n",
    "y_prediction = y_scaler.inverse_transform(y_pred.reshape(len(y_pred), 1))\n",
    "y_t = y_scaler.inverse_transform(y_test.reshape(len(y_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "02756a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_prediction: [167.32736676  82.74866116  31.77178019 145.38962379]\n",
      "y_true: [155.  82.  38. 135.]\n"
     ]
    }
   ],
   "source": [
    "print(f'y_prediction: {y_prediction.reshape(-1, )}') \n",
    "print(f'y_true: {y_t.reshape(-1, )}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
